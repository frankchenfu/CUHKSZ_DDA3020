{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1\n",
    "* Implementing Kmeans, GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X, k=3, max_iter=1000):\n",
    "\t\"\"\"\n",
    "\tX: data\n",
    "\tk: number of clusters\n",
    "\tmax_iter: maximum number of iterations\n",
    "\t\"\"\"\n",
    "\tkey = X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "\tfor _ in range(max_iter):\n",
    "\t\tdis = np.linalg.norm(X[:, None, :] - key[None, :, :], axis=2)\n",
    "\t\ttyp = np.argmin(dis, axis=1)\n",
    "\t\tkey_ = np.array([np.mean(X[typ == i], axis=0) for i in range(k)])\n",
    "\t\tif np.all(np.linalg.norm(key - key_, axis=1) < 1e-5):\n",
    "\t\t\tbreak\n",
    "\t\tkey = key_\n",
    "\treturn typ, key\n",
    "\n",
    "def __normal_distribution(X, mu, sigma):\n",
    "\t\"\"\"\n",
    "\tX: data\n",
    "\tmu: mean\n",
    "\tsigma: covariance matrix\n",
    "\tNote that the result ignored the constant term (2*pi) ** (-0.5)\n",
    "\t\"\"\"\n",
    "\treturn np.linalg.det(sigma) ** (-0.5) * np.exp(-0.5 * np.sum((X - mu) @ np.linalg.inv(sigma) * (X - mu), axis=1))\n",
    "def GMM(X, k=3, max_iter=1000):\n",
    "\t\"\"\"\n",
    "\tX: data\n",
    "\tk: number of clusters\n",
    "\tmax_iter: maximum number of iterations\n",
    "\t\"\"\"\n",
    "\tn, d = X.shape\n",
    "\tmu = X[np.random.choice(n, k, replace=False)]\n",
    "\tsigma = np.array([np.eye(d) for _ in range(k)])\n",
    "\tpi = np.ones(k) / k\n",
    "\tfor _ in range(max_iter):\n",
    "\t\t# E step\n",
    "\t\tp = np.array([pi[i] * __normal_distribution(X, mu[i], sigma[i]) for i in range(k)])\n",
    "\t\tp /= np.sum(p, axis=0, keepdims=True)\n",
    "\t\t# M step\n",
    "\t\tpi = np.mean(p, axis=1)\n",
    "\t\tmu = np.sum(p[:, :, None] * X[None, :, :], axis=1) / np.sum(p, axis=1, keepdims=True)\n",
    "\t\tsigma = np.sum(p[:, :, None, None] * (X[None, :, :, None] - mu[:, None, :, None]) * (X[None, :, None, :] - mu[:, None, None, :]), axis=1) / np.sum(p, axis=1).reshape(-1, 1, 1)\n",
    "\treturn np.argmax(p, axis=0), mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* implementing silhouette coefficient, RI, NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(X, typ):\n",
    "\t\"\"\"\n",
    "\tX: data\n",
    "\ttyp: cluster type\n",
    "\t\"\"\"\n",
    "\tif np.unique(typ).shape[0] == 1:\n",
    "\t\treturn \"N/A\"\n",
    "\tn = X.shape[0]\n",
    "\tdis = np.linalg.norm(X[:, None, :] - X[None, :, :], axis=2)\n",
    "\tdis_cluster = np.array([np.mean(dis[typ == i], axis=0) for i in range(np.max(typ) + 1)])\n",
    "\ta = np.array([dis_cluster[typ[i], i] for i in range(n)])\n",
    "\tb = np.array([np.min(np.delete(dis_cluster[:, i], typ[i])) for i in range(n)])\n",
    "\treturn np.mean((b - a) / np.maximum(a, b))\n",
    "\n",
    "def rand_index(cls1, cls2):\n",
    "\t\"\"\"\n",
    "\tcls1: cluster type 1\n",
    "\tcls2: cluster type 2\n",
    "\t\"\"\"\n",
    "\tn = cls1.shape[0]\n",
    "\ta = np.sum((cls1[:, None] == cls1[None, :]) & (cls2[:, None] == cls2[None, :])) - n\n",
    "\tb = np.sum((cls1[:, None] != cls1[None, :]) & (cls2[:, None] != cls2[None, :]))\n",
    "\treturn (a + b) / (n * (n - 1))\n",
    "\n",
    "def __entropy(cls):\n",
    "\tn = cls.shape[0]\n",
    "\ttyp = np.unique(cls)\n",
    "\treturn -np.sum([np.sum(cls == i) / n * np.log2(np.sum(cls == i) / n) for i in typ])\n",
    "def __mutual_info(cls1, cls2):\n",
    "\tn = cls1.shape[0]\n",
    "\ttyp1, typ2 = np.unique(cls1), np.unique(cls2)\n",
    "\treturn np.sum([\n",
    "\t\tnp.sum((cls1 == i) & (cls2 == j)) / n * # P(i, j)\n",
    "\t\tnp.log2(n * np.sum((cls1 == i) & (cls2 == j)) / np.sum(cls1 == i) / np.sum(cls2 == j)) # log(P(i, j) / P(i) / P(j))\n",
    "\t\tfor i in typ1 for j in typ2 if np.sum((cls1 == i) & (cls2 == j)) > 0\n",
    "\t])\n",
    "def NMI(cls1, cls2):\n",
    "\t\"\"\"\n",
    "\tcls1: cluster type 1\n",
    "\tcls2: cluster type 2\n",
    "\t\"\"\"\n",
    "\tif np.unique(cls1).shape[0] == 1 or np.unique(cls2).shape[0] == 1:\n",
    "\t\treturn \"N/A\"\n",
    "\treturn __mutual_info(cls1, cls2) / np.sqrt(__entropy(cls1) * __entropy(cls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing \"seeds.csv\"...\n",
      "k = 1 | K-means | silhouette = N/A | RI = 0.33014354066985646 | NMI = N/A\n",
      "k = 1 |   GMM   | silhouette = N/A | RI = 0.33014354066985646 | NMI = N/A\n",
      "\n",
      "k = 2 | K-means | silhouette = 0.5228955002005704 | RI = 0.7309637730690363 | NMI = 0.552245032504209\n",
      "k = 2 |   GMM   | silhouette = 0.46407877368925843 | RI = 0.7356573251310093 | NMI = 0.571759581708631\n",
      "\n",
      "k = 3 | K-means | silhouette = 0.47570673587797513 | RI = 0.8713602187286398 | NMI = 0.7100683008832274\n",
      "k = 3 |   GMM   | silhouette = 0.4625726308049252 | RI = 0.8350877192982457 | NMI = 0.6542633325693802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing \\\"seeds.csv\\\"...\")\n",
    "df = pd.read_csv(\"seeds.csv\")\n",
    "X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
    "\n",
    "for k in range(1, 4):\n",
    "\ttyp, key = Kmeans(X, k)\n",
    "\tprint(f\"k = {k} | K-means | silhouette = {silhouette(X, typ)} | RI = {rand_index(y, typ)} | NMI = {NMI(y, typ)}\")\n",
    "\ttyp, key = GMM(X, k)\n",
    "\tprint(f\"k = {k} |   GMM   | silhouette = {silhouette(X, typ)} | RI = {rand_index(y, typ)} | NMI = {NMI(y, typ)}\")\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing \"Vowel.csv\"...\n",
      "k = 1 | K-means | silhouette = N/A | RI = 0.08998988877654196 | NMI = N/A\n",
      "k = 1 |   GMM   | silhouette = N/A | RI = 0.08998988877654196 | NMI = N/A\n",
      "\n",
      "k = 2 | K-means | silhouette = 0.49158686786902217 | RI = 0.49767441860465117 | NMI = 0.0\n",
      "k = 2 |   GMM   | silhouette = 0.4805860969603036 | RI = 0.4979277098589535 | NMI = 0.0010904873313119184\n",
      "\n",
      "k = 3 | K-means | silhouette = 0.38378410361741594 | RI = 0.6359959555106168 | NMI = 0.0\n",
      "k = 3 |   GMM   | silhouette = 0.3560268360194179 | RI = 0.6077723646985528 | NMI = 0.002008103084793696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing \\\"Vowel.csv\\\"...\")\n",
    "df = pd.read_csv(\"Vowel.csv\")\n",
    "X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
    "uni = list(np.unique(y))\n",
    "y = np.array([uni.index(i) for i in y])\n",
    "\n",
    "for k in range(1, 4):\n",
    "\ttyp, key = Kmeans(X, k)\n",
    "\tprint(f\"k = {k} | K-means | silhouette = {silhouette(X, typ)} | RI = {rand_index(y, typ)} | NMI = {NMI(y, typ)}\")\n",
    "\ttyp, key = GMM(X, k)\n",
    "\tprint(f\"k = {k} |   GMM   | silhouette = {silhouette(X, typ)} | RI = {rand_index(y, typ)} | NMI = {NMI(y, typ)}\")\n",
    "\tprint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
